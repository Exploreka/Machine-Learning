# -*- coding: utf-8 -*-
"""[FIX] RecommenderNet Collaborative Filtering.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1S0AOt60ZFsz2AzyEeVv2VOe_xb1_NLqc

# Preparation

## Import Library and Data
"""

import pandas as pd
import numpy as np
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from sklearn.model_selection import train_test_split

tourism_rating = pd.read_csv('tourism_rating.csv')
tourism_with_id = pd.read_csv('tourism_with_id2.csv')

"""## Preprocessing"""

tourism_with_id.head()

tourism_with_id.isna().sum()

tourism_with_id.drop(['rating_avg_attraction'],axis=1,inplace=True)
tourism_with_id

"""## Modeling"""

user_ids = tourism_rating['id_user'].unique().tolist()
print('UserID list:', user_ids)

# Encode user IDs
user_to_user_encoded = {x: i for i, x in enumerate(user_ids)}
print('Encoded UserID:', user_to_user_encoded)

# Decoding encoded user IDs
user_encoded_to_user = {i: x for i, x in enumerate(user_ids)}
print('Decoded encoded User IDs:', user_encoded_to_user)

# Convert placeID to a list without duplicate values
place_ids = tourism_rating['id_attraction'].unique().tolist()
 
# Encoding placeID
place_to_place_encoded = {x: i for i, x in enumerate(place_ids)}
 
# Decoding encoded values to placeID
place_encoded_to_place = {i: x for i, x in enumerate(place_ids)}

# Mapping userID to the user dataframe
tourism_rating['id_user'] = tourism_rating['id_user'].map(user_to_user_encoded)
 
# Mapping placeID to the place dataframe
tourism_rating['id_attraction'] = tourism_rating['id_attraction'].map(place_to_place_encoded)

# Getting the number of users
num_users = len(user_to_user_encoded)
print(num_users)
 
# Getting the number of places
num_place = len(place_encoded_to_place)
print(num_place)
 
# Converting the rating to float values
tourism_rating['rating'] = tourism_rating['rating'].values.astype(np.float32)
 
# Minimum rating value
min_rating = min(tourism_rating['rating'])
 
# Maximum rating value
max_rating = max(tourism_rating['rating'])
 
print('Number of User: {}, Number of place: {}, Min Rating: {}, Max Rating: {}'.format(
    num_users, num_place, min_rating, max_rating
))

collab_filtering = tourism_rating.sample(frac=1, random_state=42)
collab_filtering

x = collab_filtering[['id_user', 'id_attraction']].values
 
# Creating the variable y to represent the ratings
y = collab_filtering['rating'].apply(lambda x: (x - min_rating) / (max_rating - min_rating)).values
 
# Splitting the data into 80% for training and 20% for validation
x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=0.2, random_state=42)

print("Training data:")
print(x_train, y_train)
print("Validation data:")
print(x_val, y_val)

class RecommenderNet(tf.keras.Model):
 
  # Function Initialization
  def __init__(self, num_users, num_place, embedding_size, **kwargs):
    super(RecommenderNet, self).__init__(**kwargs)
    self.num_users = num_users
    self.num_place = num_place
    self.embedding_size = embedding_size
    self.user_embedding = layers.Embedding( # layer embedding user
        num_users,
        embedding_size,
        embeddings_initializer = 'he_normal',
        embeddings_regularizer = keras.regularizers.l2(1e-6)
    )
    self.user_bias = layers.Embedding(num_users, 1) # layer embedding user bias
    self.place_embedding = layers.Embedding( # layer embeddings place
        num_place,
        embedding_size,
        embeddings_initializer = 'he_normal',
        embeddings_regularizer = keras.regularizers.l2(1e-6)
    )
    self.place_bias = layers.Embedding(num_place, 1) # layer embedding place bias
 
  def call(self, inputs):
    user_vector = self.user_embedding(inputs[:, 0]) # calling embedding layer 1
    user_bias = self.user_bias(inputs[:, 0]) # calling embedding layer 2
    place_vector = self.place_embedding(inputs[:, 1]) # calling embedding layer 3
    place_bias = self.place_bias(inputs[:, 1]) # calling embedding layer 4

    dot_user_place = tf.tensordot(user_vector, place_vector, 2)

    x = dot_user_place + user_bias + place_bias

    return tf.nn.sigmoid(x) # sigmoid activation

# Model Initialization
model = RecommenderNet(num_users, num_place, 50)
 
# Model Compile
model.compile(
    loss=tf.keras.losses.BinaryCrossentropy(),
    optimizer=keras.optimizers.Adagrad(learning_rate=0.05),
    metrics=[tf.keras.metrics.RootMeanSquaredError()]
)

history = model.fit(
    x = x_train,
    y = y_train,
    batch_size = 8,
    epochs = 100,
    validation_data = (x_val, y_val)
)

place_df = tourism_with_id
df = tourism_rating
 
# User Sample
id_user = df.id_user.sample(1).iloc[0]
place_visited_by_user = df[df.id_user == id_user]

place_not_visited = place_df[~place_df['id_attraction'].isin(place_visited_by_user.id_attraction.values)]['id_attraction']
place_not_visited = list(
    set(place_not_visited)
    .intersection(set(place_to_place_encoded.keys()))
)
 
place_not_visited = [[place_to_place_encoded.get(x)] for x in place_not_visited]
user_encoder = user_to_user_encoded.get(id_user)
user_place_array = np.hstack(
    ([[user_encoder]] * len(place_not_visited), place_not_visited)
)

ratings = model.predict(user_place_array).flatten()

top_ratings_indices = ratings.argsort()[-10:][::-1]
recommended_place_ids = [
    place_encoded_to_place.get(place_not_visited[x][0]) for x in top_ratings_indices
]

print('Showing recommendations for users: {}'.format(id_user))
print('place with high ratings from user')
print('----' * 8)

top_place_user = (
    place_visited_by_user.sort_values(
        by = 'rating',
        ascending=False
    )
    .head(5)
    .id_attraction.values
)

place_df_rows = place_df[place_df['id_attraction'].isin(top_place_user)]
for row in place_df_rows.itertuples():
    print(row.name_attraction)
 
print('----' * 8)
print('Top 10 place recommendation')
print('----' * 8)

recommended_place = place_df[place_df['id_attraction'].isin(recommended_place_ids)]
for row in recommended_place.itertuples():
    print(row.name_attraction)

"""## Save Model"""

## .H5

model.save_weights("model.h5")

export_dir = 'saved_model/1'

tf.saved_model.save(model,export_dir=export_dir)

# Convert the model.
converter = tf.lite.TFLiteConverter.from_saved_model(export_dir)
tflite_model = converter.convert()

# Save the model.
with open('model.tflite', 'wb') as f:
  f.write(tflite_model)

"""## Download the Model"""

try:
    from google.colab import files
    files.download(tflite_model_file)
except:
    pass

